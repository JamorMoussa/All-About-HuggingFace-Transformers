{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b1abc7-a7d6-4d39-8762-a5522f22d85e",
   "metadata": {},
   "source": [
    "# HuggingFace's Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9d2f4-063c-44ab-96d2-b95c417ec0eb",
   "metadata": {},
   "source": [
    "## 01. The Pipeline function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0755596c-d773-4944-832f-7087ee36e368",
   "metadata": {},
   "source": [
    "The Hugging Face's transformers library provides a `pipeline` API, that enables us to create pipelines and use pre-trained models, for specific tasks without handling the complex deep learning concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d022b337-bd9c-40eb-90d7-9dd6e11dedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae62b7-e9e8-4da3-a883-cf22ceaf5e73",
   "metadata": {},
   "source": [
    "### 1.1 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fd574-c2e1-48ff-a6f6-350094c5f532",
   "metadata": {},
   "source": [
    "For instance, we use the `sentiment-analysis` or `text-classification` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74f3cd3b-3e08-463f-a2c1-6539a2a9d691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d85cda-f408-4020-a662-a30a45b3d676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.text_classification.TextClassificationPipeline object at 0x7c838e1198d0>\n"
     ]
    }
   ],
   "source": [
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f28e18-0531-4acb-a796-d2aa689580ce",
   "metadata": {},
   "source": [
    "Let's see the model used for the `sentiment-analysis` task. They use the BERT model, the encoder only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "529bd9fe-9fde-4647-90e1-26ce1ffc4ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396943fe-3998-43e5-8814-bce48e60df27",
   "metadata": {},
   "source": [
    "Our `classifier` is a `TextClassificationPipeline` pipeline object. It's designed to work with text classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98effdd4-6549-41a2-84ec-5cdc69fcdfa9",
   "metadata": {},
   "source": [
    "The `classifier` accepts a sentence or list of sentences as input. For instance, we pass a single sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44c28c4a-8bb7-4eac-9ee4-0a6c8d08ebee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.994739830493927}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a404559-7c24-42ef-ae6f-046a483b9c10",
   "metadata": {},
   "source": [
    "Beautiful, the `classifier`, returns a dictionary containing two results, the `label` and the `score`, that measure how the model is confident on that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38b53f8-c8db-4cd3-a3ee-a7fc320fb55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9965726137161255}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"hey, wait what are you doing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a6a71-323b-4284-803c-51218a26ffa8",
   "metadata": {},
   "source": [
    "The `pipeline` for sentiment analysis supports, passing multiple sentences. Let's check it out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68170fa1-8ed6-4b42-bf92-c6ff1f78e94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9983717799186707},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\n",
    "        \"I've been waiting for hugging face course my whole life.\", \"I hate this so much!\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794a188-1d98-4e31-9cd4-937acba9e081",
   "metadata": {},
   "source": [
    "### 1.2 Zero-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25577743-449f-4657-8375-1ca461e1e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc1b71-c4f8-4218-a53c-a667e92d7611",
   "metadata": {},
   "source": [
    "The model used here is the `Bart` model, they use specifically  the `BartForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9b2d2b4-0506-42a4-bba1-33db7b14e0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForSequenceClassification(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): BartClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b20eda7-2f40-430d-9dbf-e0488fa21a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTokenizerFast(name_or_path='facebook/bart-large-mnli', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b37ec1c-2e3c-4e7f-a1ac-9ac42680ec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library, with Python programming language',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.9771820306777954, 0.015976309776306152, 0.0068415747955441475]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    sequences=\"This is a course about the Transformers library, with Python programming language\", \n",
    "    candidate_labels = [\"education\", \"business\", \"politics\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bddab2-b957-4e28-a8f6-ee6ad888bf18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a18e165-edc4-4a67-8b40-9995845a04e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e748e4-9225-4b58-a1de-dd36ffc5cff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
